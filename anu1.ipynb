{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anu1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdPnLVWDbTW948sPCUvVLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhaechang/digital/blob/main/anu1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSn4X_aypgVA"
      },
      "source": [
        "import functools\n",
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"TF-Hub version: \", hub.__version__)\n",
        "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
        "print(\"GPU available: \", tf.test.is_gpu_available())\n",
        "\n",
        "\n",
        "# @title Define image loading and visualization functions  { display-mode: \"form\" }\n",
        "\n",
        "def crop_center(image):\n",
        "  \"\"\"Returns a cropped square image.\"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape)\n",
        "  return image\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img = plt.imread(image_path).astype(np.float32)[np.newaxis, ...]\n",
        "  if img.max() > 1.0:\n",
        "    img = img / 255.\n",
        "  if len(img.shape) == 3:\n",
        "    img = tf.stack([img, img, img], axis=-1)\n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  return img\n",
        "\n",
        "def show_n(images, titles=('',)):\n",
        "  n = len(images)\n",
        "  image_sizes = [image.shape[1] for image in images]\n",
        "  w = (image_sizes[0] * 6) // 320\n",
        "  plt.figure(figsize=(w  * n, w))\n",
        "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
        "  for i in range(n):\n",
        "    plt.subplot(gs[i])\n",
        "    plt.imshow(images[i][0], aspect='equal')\n",
        "    plt.axis('off')\n",
        "    plt.title(titles[i] if len(titles) > i else '')\n",
        "  plt.show()\n",
        "\n",
        "# @title Load example images  { display-mode: \"form\" }\n",
        "\n",
        "content_image_url = 'https://postfiles.pstatic.net/MjAyMDExMDJfMzUg/MDAxNjA0MzA0Nzg5NzEz.DceECrLsPnkc-Qf5I9LkIFY3-LGbxTIe1z5Te3HUwSgg.eaBDLjrTF-fz1RKL8Pe6uFa_bquW8cuLgqW-aLpdU3og.JPEG.khc9812121/KakaoTalk_20201102_112212199.jpg?type=w580'  # @param {type:\"string\"}\n",
        "style_image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'  # @param {type:\"string\"}\n",
        "output_image_size = 384  # @param {type:\"integer\"}\n",
        "\n",
        "# The content image size can be arbitrary.\n",
        "content_img_size = (output_image_size, output_image_size)\n",
        "# The style prediction model was trained with image size 256 and it's the \n",
        "# recommended image size for the style image (though, other sizes work as \n",
        "# well but will lead to different results).\n",
        "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "content_image = load_image(content_image_url, content_img_size)\n",
        "style_image = load_image(style_image_url, style_img_size)\n",
        "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "show_n([content_image, style_image], ['Content image', 'Style image'])\n",
        "\n",
        "# Load TF-Hub module.\n",
        "\n",
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)\n",
        "\n",
        "# Stylize content image with given style image.\n",
        "# This is pretty fast within a few milliseconds on a GPU.\n",
        "\n",
        "outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "stylized_image = outputs[0]\n",
        "\n",
        "show_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
